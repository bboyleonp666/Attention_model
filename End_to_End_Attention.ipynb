{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/tutorials/text/nmt_with_attention\n",
    "import tensorflow as tf\n",
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa # for audio processing\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile # for audio processing\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveReader:\n",
    "    def __init__(self, path, sample_rate, padding_type, read_size):\n",
    "        '''\n",
    "        Args:\n",
    "            path: train path containing directory which one would like to load\n",
    "            sample_rate: sample rate for reading .wav file\n",
    "            padding_type: padding for .wav data length less than 1 second\n",
    "            read_size: size that one would like to read\n",
    "        '''\n",
    "        \n",
    "        self.path = path\n",
    "        self.sample_rate = sample_rate\n",
    "        self.padding_type = padding_type\n",
    "        self.read_size = read_size\n",
    "\n",
    "    def read(self, labels=None):\n",
    "        print(\"LABEL\\tTOTAL\\tREAD\\tSAVED\\t<1s COUNT\")\n",
    "        print(\"-----\\t-----\\t----\\t-----\\t---------\")\n",
    "        \n",
    "        if labels is None:\n",
    "            labels = [f for f in os.listdir(path) if os.path.isdir(path + \"\\\\\" + f)]\n",
    "            \n",
    "        elif type(labels) == str:\n",
    "            samples, total_wave_count, total_wave_read, total_loss_count = self.read_dir(dir_name=labels)\n",
    "            sample_labels = np.repeat(labels, total_wave_read)\n",
    "            \n",
    "            print(\"\\n\\nMISSION COMPELTE!!!\")\n",
    "            return samples, sample_labels, total_wave_count, total_loss_count\n",
    "                    \n",
    "        label_len = len(labels)\n",
    "        total_wave_count = np.zeros(label_len, dtype=np.int32)\n",
    "        total_wave_read = np.zeros(label_len, dtype=np.int32)\n",
    "        total_loss_count = np.zeros(label_len, dtype=np.int32)\n",
    "\n",
    "        \n",
    "        for i, lab in enumerate(labels):\n",
    "            samp, total_wave_count[i], total_wave_read[i], total_loss_count[i] = self.read_dir(dir_name=lab)\n",
    "            \n",
    "            if i == 0:\n",
    "                samples = samp\n",
    "                sample_labels = np.repeat(lab, total_wave_read[i])\n",
    "            else:\n",
    "                samples = np.concatenate((samples, samp), axis=0)\n",
    "                sample_labels = np.concatenate((sample_labels, np.repeat(lab, total_wave_read[i])), axis=None)\n",
    "        \n",
    "        print(\"\\n\\nMISSION COMPELTE!!!\")\n",
    "        return samples, sample_labels, total_wave_count, total_loss_count\n",
    "    \n",
    "    def read_dir(self, dir_name):\n",
    "        dir_path = os.path.join(self.path, dir_name)\n",
    "        wave_files = [f for f in os.listdir(dir_path) if f.endswith('.wav')]\n",
    "        total_wave_files = len(wave_files)\n",
    "\n",
    "        if self.read_size is not None:\n",
    "            wave_files_read = self.read_size\n",
    "        else:\n",
    "            wave_files_read = total_wave_files\n",
    "\n",
    "        samples = np.zeros((wave_files_read, self.sample_rate))\n",
    "        less_than_1s_count = 0\n",
    "        num_of_file_read = 0\n",
    "        for i, wav_file in enumerate(wave_files):\n",
    "            wave_file_path = os.path.join(dir_path, wav_file)\n",
    "            samp, _ = librosa.load(wave_file_path, sr=self.sample_rate)\n",
    "\n",
    "            pad_size = self.sample_rate - len(samp)\n",
    "            if pad_size > 0:\n",
    "                less_than_1s_count += 1\n",
    "                if self.padding_type is None:\n",
    "                    # None: than skip this wave file\n",
    "                    continue\n",
    "\n",
    "                elif self.padding_type == \"white_noise\":\n",
    "                    # white_noise: pad white noise data behind\n",
    "                    padding = np.random.normal(0, 0.02, pad_size)\n",
    "                    samples[i, :] = np.concatenate((samp, padding), axis=None)\n",
    "                    num_of_file_read += 1\n",
    "\n",
    "\n",
    "                elif self.padding_type == \"zero\":\n",
    "                    # zero: pad zeros behind\n",
    "                    padding = np.zeros(pad_size)\n",
    "                    samples[i, :] = np.concatenate((samp, padding), axis=None)\n",
    "                    num_of_file_read += 1\n",
    "            else:\n",
    "                num_of_file_read += 1\n",
    "                \n",
    "\n",
    "            print(\"{}\\t{}\\t{}\\t{}\\t{}\".format(dir_name, \n",
    "                                              total_wave_files, \n",
    "                                              i+1, \n",
    "                                              num_of_file_read, \n",
    "                                              less_than_1s_count), end=\"\\r\")\n",
    "            \n",
    "            if num_of_file_read == wave_files_read:\n",
    "                break\n",
    "                \n",
    "        print()\n",
    "\n",
    "        return samples, total_wave_files, wave_files_read, less_than_1s_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL\tTOTAL\tREAD\tSAVED\t<1s COUNT\n",
      "-----\t-----\t----\t-----\t---------\n",
      "zero\t2376\t2160\t2000\t160\n",
      "one\t2370\t2262\t2000\t262\n",
      "two\t2373\t2222\t2000\t222\n",
      "three\t2356\t2207\t2000\t207\n",
      "four\t2372\t2201\t2000\t201\n",
      "five\t2357\t2185\t2000\t185\n",
      "six\t2369\t2164\t2000\t164\n",
      "seven\t2377\t2194\t2000\t194\n",
      "eight\t2352\t2232\t2000\t232\n",
      "nine\t2364\t2178\t2000\t178\n",
      "\n",
      "\n",
      "MISSION COMPELTE!!!\n",
      "\n",
      "Check the existence of NaN and Inf\n",
      "NaN Number: 0\n",
      "Inf Number: 0\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_RATE = 16000\n",
    "\n",
    "train_audio_path = os.path.join(os.path.dirname(os.getcwd()), \"data\", \"train\", \"audio\")\n",
    "phoneme_path = os.path.join(os.getcwd(), \"Phonemes\")\n",
    "phoneme_dataframe = pd.read_csv(os.path.join(phoneme_path, \"phonemes.csv\"))\n",
    "\n",
    "reader = WaveReader(path=train_audio_path, \n",
    "                    sample_rate=SAMPLE_RATE, \n",
    "                    padding_type=None, \n",
    "                    read_size=2000)\n",
    "\n",
    "wav_array, label_array, total, loss = reader.read(labels=phoneme_dataframe.words)\n",
    "\n",
    "print(\"\\nCheck the existence of NaN and Inf\")\n",
    "print(f\"NaN Number: {np.sum(np.isnan(wav_array))}\")\n",
    "print(f\"Inf Number: {np.sum(np.isinf(wav_array))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocesser:\n",
    "    def __init__(self, create_size, min_sz=6, max_sz=8, padding_type=\"zero\"):\n",
    "        '''\n",
    "        Args:\n",
    "            create_size: size of binding wave one would like to create\n",
    "            min_sz: minimum size of wave data\n",
    "            max_sz: maximum size of wave data\n",
    "            padding_type: padding for .wav data length less than 1 second\n",
    "        '''\n",
    "        self.create_size = create_size\n",
    "        self.min_sz = min_sz\n",
    "        self.max_sz = max_sz\n",
    "        self.padding_type = padding_type\n",
    "\n",
    "    def simulate_wave(self, waves):\n",
    "        '''\n",
    "        method for simulating wave inputs\n",
    "        which will concatenate audio inputs for building longer audio dataset\n",
    "        '''\n",
    "        # get picker for combining waves and labels(phonemes)\n",
    "        self.wave_shape = waves.shape\n",
    "        self.pickers = self.get_picker()\n",
    "        \n",
    "        print(\"Wave Data Simulation ... \", end=\"\")\n",
    "        \n",
    "        binded_length = self.wave_shape[1]*self.max_sz\n",
    "        simu_wave = np.zeros((self.create_size, binded_length))\n",
    "        \n",
    "        \n",
    "        for i, picker in enumerate(self.pickers):        \n",
    "            tmp_simu_wave = np.array([waves[p] for p in picker]).flatten()\n",
    "            \n",
    "            pad_size = binded_length - len(tmp_simu_wave)\n",
    "            if pad_size > 0:\n",
    "                if self.padding_type == \"white_noise\":\n",
    "                    # padding white noise\n",
    "                    padding = np.random.normal(0, 0.02, size=pad_size)\n",
    "\n",
    "                elif self.padding_type == \"zero\":\n",
    "                    # padding zeros\n",
    "                    padding = np.zeros(pad_size)\n",
    "\n",
    "                simu_wave[i] = np.concatenate((tmp_simu_wave, padding), axis=None)\n",
    "                \n",
    "            else:\n",
    "                simu_wave[i] = tmp_simu_wave\n",
    "            \n",
    "        print(\"Done\")\n",
    "        return simu_wave\n",
    "    \n",
    "    def get_picker(self):\n",
    "        '''\n",
    "        picker stands for index pick\n",
    "        this is for combining audio data with decided minimum and maximum size\n",
    "        '''\n",
    "        size = np.random.randint(low=self.min_sz, \n",
    "                                 high=self.max_sz+1, \n",
    "                                 size=self.create_size)\n",
    "\n",
    "        picker = np.zeros(self.create_size, dtype=np.object)\n",
    "        for i, s in enumerate(size):\n",
    "            picker[i] = np.random.choice(self.wave_shape[0]-1, size=self.max_sz, replace=False)[:s]\n",
    "            \n",
    "        return picker\n",
    "\n",
    "    def simulate_label(self, labels):\n",
    "        '''\n",
    "        method for simulating label inputs\n",
    "        which will concatenate audio labels for following audio dataset we built\n",
    "        '''\n",
    "        print(\"Label Simulation ... \", end=\"\")\n",
    "        \n",
    "        simu_label = np.zeros(self.create_size, dtype=np.object)\n",
    "        for i, picker in enumerate(self.pickers):\n",
    "            simu_label[i] = np.array([labels[p] for p in picker])\n",
    "            \n",
    "        print(\"Done\")\n",
    "        return simu_label\n",
    "\n",
    "    def simulate_phoneme(self, labels, label_dict, phoneme_dict):\n",
    "        '''\n",
    "        method for sumulating phoneme inputs\n",
    "        which will concatenate audio phonemes with labels we concated by simulate_label()\n",
    "        '''\n",
    "        print(\"Phoneme Simulation... \", end=\"\")\n",
    "        \n",
    "        self.label_dict = label_dict\n",
    "        self.phoneme_dict = phoneme_dict\n",
    "\n",
    "        simu_phoneme = np.empty(self.create_size, dtype=np.object)\n",
    "        for i, label in enumerate(labels):\n",
    "            simu_phoneme[i] = \" \".join([self.phoneme_translator(lab) for lab in label])\n",
    "            simu_phoneme[i] = \"<start> \" + simu_phoneme[i] + \" <end>\"\n",
    "            \n",
    "        print(\"Done\")\n",
    "        return simu_phoneme\n",
    "\n",
    "    def phoneme_translator(self, input_label):\n",
    "        '''\n",
    "        translate labels to phoneme if simulate_phoneme is called\n",
    "        '''\n",
    "        for i, label in enumerate(self.label_dict):\n",
    "            if input_label == label:\n",
    "                return self.phoneme_dict[i]\n",
    "            \n",
    "    def tokenize(self, phoneme):\n",
    "        '''\n",
    "        with tensorflow we can simply apply Tokenizer for text(in our case, phoneme)\n",
    "        to generate phoneme outputs\n",
    "        '''\n",
    "        tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "        tokenizer.fit_on_texts(phoneme)\n",
    "        tensor = tokenizer.texts_to_sequences(phoneme)\n",
    "        tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "        return tensor, tokenizer\n",
    "\n",
    "    def show_convert(self, tensor, tokenizer):\n",
    "        '''\n",
    "        showing case of tokenized word according to its index\n",
    "        '''\n",
    "        print(\"\\nTOKEN\\t--->\\tWORDS\")\n",
    "        print(\"-----------------------\")\n",
    "        for t in tensor:\n",
    "            if t != 0:\n",
    "                print(\"{}\\t--->\\t{}\".format(t, tokenizer.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wave Data Simulation ... Done\n",
      "Label Simulation ... Done\n",
      "Phoneme Simulation... Done\n",
      "\n",
      "Example Label Display: ['seven' 'two' 'zero' 'six']\n",
      "Example Phoneme Display: <start> S EH V AH N T UW Z IY R OW S IH K S <end>\n"
     ]
    }
   ],
   "source": [
    "CREATE_SIZE = 20000\n",
    "MIN_BINDING_SIZE = 1\n",
    "MAX_BINDING_SIZE = 1\n",
    "\n",
    "preprocesser = Preprocesser(create_size=CREATE_SIZE, \n",
    "                            min_sz=MIN_BINDING_SIZE, \n",
    "                            max_sz=MAX_BINDING_SIZE, \n",
    "                            padding_type=\"zero\")\n",
    "\n",
    "simu_wave = preprocesser.simulate_wave(wav_array)\n",
    "simu_label = preprocesser.simulate_label(label_array)\n",
    "simu_phoneme = preprocesser.simulate_phoneme(labels=simu_label, \n",
    "                                             label_dict=phoneme_dataframe.words.values, \n",
    "                                             phoneme_dict=phoneme_dataframe.phonemes.values)\n",
    "\n",
    "print(f\"\\nExample Label Display: {simu_label[0]}\")\n",
    "print(f\"Example Phoneme Display: {simu_phoneme[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFCC:\n",
    "    '''\n",
    "    This is the Mel-Frequency Cepstral Coefficients, MFCCs Transformation\n",
    "    including\n",
    "        1. Pre-emphasis\n",
    "        2. Framing\n",
    "        3. Hamming window\n",
    "        4. Short-time Fourier Transform\n",
    "        5. Mel triangular bandpass filters\n",
    "        6. Log energy\n",
    "        \n",
    "    not including\n",
    "        7. Discrete cosine transform\n",
    "        8. Delta cepstrum\n",
    "    '''\n",
    "    def __init__(self, alpha, frame_size, frame_stride, n_fft, n_filter):\n",
    "        '''\n",
    "        Args:\n",
    "            alpha: coefficient applied when applying pre-emphasis, usually between (0.95, 0.98)\n",
    "            frame_size: duration of one frame in second\n",
    "            frame_stride: stride duration of one frame in second\n",
    "            n_fft: decided number while applying Fast Fourier Transformation\n",
    "        '''\n",
    "        self.alpha = alpha\n",
    "        self.frame_size = frame_size\n",
    "        self.frame_stride = frame_stride\n",
    "        self.n_fft = n_fft\n",
    "        self.n_filter = n_filter\n",
    "        \n",
    "    def mfcc(self, samples, sample_rate):\n",
    "        samples_emphasized = self.pre_emphasis(samples)\n",
    "        frames, total_samples_in_frame = self.framing(samples_emphasized, sample_rate)\n",
    "        frames = self.hamming_window(frames, total_samples_in_frame)\n",
    "        power_spectrum = self.stft(frames)\n",
    "        fbank = self.filter_bank(power_spectrum, sample_rate)\n",
    "        energy = self.log_energy(fbank)\n",
    "        \n",
    "        return np.column_stack((energy, fbank))\n",
    "    \n",
    "    def pre_emphasis(self, samples):\n",
    "        return np.append(samples[0], samples[1:] - self.alpha*samples[:-1])\n",
    "    \n",
    "    def framing(self, samples, sample_rate):\n",
    "        samples_in_frame = int(np.ceil(self.frame_size*sample_rate))                           # number of samples in one frame\n",
    "        sample_stride = int(np.ceil(self.frame_stride*sample_rate))                            # sample stride in each iteration\n",
    "        frame_num = int(np.ceil(\n",
    "            (len(samples) - samples_in_frame)/sample_stride) + 1)                              # number of iterations\n",
    "\n",
    "        padding_num = (frame_num-1)*sample_stride + samples_in_frame - len(samples)            # length for padding\n",
    "        padding = np.zeros(padding_num)                                                        # prepare the padding array\n",
    "        samples_padded = np.append(samples, padding)                                           # padded sample array\n",
    "\n",
    "        # index to pick all the overlapping samples\n",
    "        index_each_frame = np.arange(samples_in_frame)\n",
    "        index_each_stride = np.linspace(0, len(samples_padded) - samples_in_frame, frame_num).astype(np.int32)\n",
    "        index = np.tile(index_each_frame, reps=(frame_num, 1)) + np.tile(index_each_stride, reps=(samples_in_frame, 1)).T\n",
    "\n",
    "        return np.array([samples_padded[[i]] for i in index]), samples_in_frame                # frames is a 2D array\n",
    "    \n",
    "        \n",
    "    def hamming_window(self, frames, samples_in_frame):\n",
    "        # self.frames *= 0.54 - 0.46 * numpy.cos((2 * numpy.pi * n) / (self.total_samples_in_one_frame - 1))\n",
    "        frames *= np.hamming(samples_in_frame)\n",
    "        return frames\n",
    "        \n",
    "    def stft(self, frames):\n",
    "        magnitude = np.abs(np.fft.rfft(frames, n=self.n_fft))                                  # magnitude of the FFT\n",
    "        return (1.0/self.n_fft) * magnitude**2                                                 # power spectrum\n",
    "    \n",
    "    def filter_bank(self, frames, sample_rate):\n",
    "        low_freq_mel = 0\n",
    "        high_freq_mel = self.hz2mel(sample_rate/2)                                             # highest frequency of the Mel\n",
    "        mel_points = np.linspace(low_freq_mel, high_freq_mel, self.n_filter+2)                 # Equally spaced in Mel scale\n",
    "        bins = np.floor((self.n_fft+1) * self.mel2hz(mel_points) / sample_rate)                # bins for FFT\n",
    "        \n",
    "        fbank = np.zeros((self.n_filter, self.n_fft//2 + 1))\n",
    "        for j in range(self.n_filter):\n",
    "            for i in range(int(bins[j]), int(bins[j+1])):\n",
    "                fbank[j, i] = (i - bins[j]) / (bins[j+1] - bins[j])\n",
    "            for i in range(int(bins[j+1]), int(bins[j+2])):\n",
    "                fbank[j, i] = (bins[j+2] - i) / (bins[j+2] - bins[j+1])\n",
    "        \n",
    "        mel_fbanks = np.dot(frames, fbank.T)\n",
    "        mel_fbanks = np.where(mel_fbanks == 0, np.finfo(float).eps, mel_fbanks)\n",
    "        mel_fbanks = 20 * np.log10(mel_fbanks)                                                 # dB\n",
    "        \n",
    "        return mel_fbanks\n",
    "        \n",
    "    def log_energy(self, mel_fbanks):\n",
    "        return np.log(np.sum(mel_fbanks**2, axis=1))\n",
    "\n",
    "    def hz2mel(self, hz):\n",
    "        return 2595 * np.log10(1 + hz/700)  # Convert Hz to Mel\n",
    "    \n",
    "    def mel2hz(self, mel):\n",
    "        return 700 * (10**(mel/2595.0) - 1) # Convert Mel to Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFCCApplier:\n",
    "    '''\n",
    "    This is the MFCC applier for applying MFCC \n",
    "    and pad zeros for fitting the data into Encoder-Decoder Model with Attention\n",
    "    which we will build later\n",
    "    '''\n",
    "    def __init__(self, alpha, frame_size, frame_stride, n_fft, n_filter, decide_size):\n",
    "        '''\n",
    "        Arg:\n",
    "            mfcc: build by MFCC class for transform inputs\n",
    "            decide_size: a 2^k number which will make the inputs reshape into X*decide_size\n",
    "                         which will help us build the pyramidal RNN encoder\n",
    "        '''\n",
    "        self.mfcc = MFCC(alpha=alpha, \n",
    "                         frame_size=frame_size, \n",
    "                         frame_stride=frame_stride, \n",
    "                         n_fft=n_fft, \n",
    "                         n_filter=n_filter)\n",
    "        \n",
    "        self.decide_size = decide_size\n",
    "        \n",
    "    def apply(self, inputs):\n",
    "        input_shape = inputs.shape\n",
    "        # print(\"Shape of inputs: (input cases, sample size) {}\".format(input_shape))\n",
    "        \n",
    "        sample = self.mfcc.mfcc(samples=inputs[0, :], sample_rate=input_shape[1])\n",
    "        sample_shape = sample.shape\n",
    "        # n_filter + 1 is the final output of MFCC\n",
    "        # 1 stands for log energy\n",
    "        print(\"Shape of inputs after MFCC: (time step, number of filters + 1) {}\\n\".format(sample_shape))\n",
    "        \n",
    "        old_size = sample_shape[1] * sample_shape[0]\n",
    "        print(\"Size after flatten: {}\".format(old_size))\n",
    "        \n",
    "        multiplier = sample_shape[1] * self.decide_size\n",
    "        new_size = int((old_size//multiplier + 1) * multiplier)\n",
    "        print(\"Size after zero padding: {}\\n\".format(new_size))\n",
    "        \n",
    "        outputs = np.zeros((input_shape[0], new_size))\n",
    "        zero_padding = np.zeros(new_size - old_size)\n",
    "        \n",
    "        for i in np.arange(input_shape[0]):\n",
    "            mfcced_wave = self.mfcc.mfcc(inputs[i, :], input_shape[1]).flatten(order=\"C\")\n",
    "            outputs[i, :] = np.concatenate((mfcced_wave, zero_padding))\n",
    "            \n",
    "            print(f\"Applying MFCC to {i+1}th case with reshaping\", end=\"\\r\")\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of inputs after MFCC: (time step, number of filters + 1) (99, 13)\n",
      "\n",
      "Size after flatten: 1287\n",
      "Size after zero padding: 1664\n",
      "\n",
      "Applying MFCC to 20000th case with reshaping\r"
     ]
    }
   ],
   "source": [
    "ALPHA = 0.95\n",
    "FRAME_SIZE = 0.025\n",
    "FRAME_STRIDE = 0.01\n",
    "N_FFT = 512\n",
    "N_FILTER = 12\n",
    "DECIDE_SIZE = 64\n",
    "\n",
    "mfcc_applier = MFCCApplier(alpha=ALPHA, \n",
    "                           frame_size=FRAME_SIZE, \n",
    "                           frame_stride=FRAME_STRIDE, \n",
    "                           n_fft=N_FFT, \n",
    "                           n_filter=N_FILTER, \n",
    "                           decide_size=DECIDE_SIZE)\n",
    "\n",
    "mfcced_simu_wave = mfcc_applier.apply(simu_wave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Shape: (20000, 26)\n",
      "Input Shape: (20000, 1664)\n",
      "\n",
      "TOKEN\t--->\tWORDS\n",
      "-----------------------\n",
      "4\t--->\t<start>\n",
      "2\t--->\ts\n",
      "16\t--->\teh\n",
      "8\t--->\tv\n",
      "9\t--->\tah\n",
      "1\t--->\tn\n",
      "6\t--->\tt\n",
      "12\t--->\tuw\n",
      "18\t--->\tz\n",
      "11\t--->\tiy\n",
      "3\t--->\tr\n",
      "19\t--->\tow\n",
      "2\t--->\ts\n",
      "14\t--->\tih\n",
      "15\t--->\tk\n",
      "2\t--->\ts\n",
      "5\t--->\t<end>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "phoneme_tensor, phoneme_tokenizer = preprocesser.tokenize(simu_phoneme)\n",
    "wav_tensor = tf.convert_to_tensor(mfcced_simu_wave, dtype=tf.float32)\n",
    "\n",
    "print(\"Output Shape: {}\".format(phoneme_tensor.shape))\n",
    "print(\"Input Shape: {}\".format(wav_tensor.shape))\n",
    "\n",
    "for tensor in phoneme_tensor[:1]:\n",
    "    preprocesser.show_convert(tensor, phoneme_tokenizer)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "LSTM_UNITS = 256\n",
    "FINAL_TIMESTEP = DECIDE_SIZE\n",
    "EMBEDDING_DIM = 64\n",
    "WAV_SIZE = len(wav_tensor)\n",
    "PHONEME_SIZE = len(phoneme_tokenizer.word_index) + 1\n",
    "STEP_PER_EPOCH = WAV_SIZE // BATCH_SIZE\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((wav_tensor, phoneme_tensor)).shuffle(WAV_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Input Shape: (1, 1664)\n",
      "Reshaped Input Shape: (1, 1664, 1)\n",
      "\n",
      "Original Output Shape: (1, 26)\n"
     ]
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "print(f\"Original Input Shape: {example_input_batch.shape}\")\n",
    "\n",
    "example_input_batch = tf.expand_dims(example_input_batch, 2)\n",
    "print(f\"Reshaped Input Shape: {example_input_batch.shape}\")\n",
    "\n",
    "print(f\"\\nOriginal Output Shape: {example_target_batch.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, lstm_units, final_units, batch_sz, mfcc_dims):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.lstm_units = lstm_units\n",
    "        self.final_units = final_units\n",
    "        self.batch_sz = batch_sz\n",
    "        self.mfcc_dims = mfcc_dims\n",
    "        \n",
    "        # build layer info dictionary\n",
    "        self.layer_info = dict()\n",
    "        \n",
    "        # Convolutional layer to extract feature after MFCC\n",
    "        self.conv_feat = tf.keras.layers.Conv1D(filters=32, \n",
    "                                                kernel_size=self.mfcc_dims, \n",
    "                                                padding='valid', \n",
    "                                                activation='relu', \n",
    "                                                strides=self.mfcc_dims)\n",
    "        \n",
    "        self.conv1 = tf.keras.layers.Conv1D(filters=32, \n",
    "                                            kernel_size=5, \n",
    "                                            padding='same', \n",
    "                                            activation='relu', \n",
    "                                            strides=1)\n",
    "        \n",
    "        self.conv2 = tf.keras.layers.Conv1D(filters=64, \n",
    "                                            kernel_size=3, \n",
    "                                            padding='same', \n",
    "                                            activation='relu', \n",
    "                                            strides=1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        '''\n",
    "        build a pyramidal LSTM neural network encoder\n",
    "        '''\n",
    "        self.layer_info[\"Input Layer\"] = inputs.shape\n",
    "        \n",
    "        # Convolution Feature Extraction\n",
    "        x = self.conv_feat(inputs)\n",
    "        self.layer_info[\"Convolution Feature Layer\"] = x.shape\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        self.layer_info[\"Convolution Layer 1\"] = x.shape\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        self.layer_info[\"Convolution Layer 2\"] = x.shape\n",
    "        \n",
    "        # initialize states for forward and backward\n",
    "        initial_state_fw = None\n",
    "        initial_state_bw = None\n",
    "        \n",
    "        pyramid_layer_number = 0\n",
    "        while(x.shape[1] > self.final_units):\n",
    "            pyramid_layer_number += 1\n",
    "            # forward LSTM\n",
    "            fw_output, fw_state_h, fw_state_c = self.build_lstm(True)(x, initial_state=initial_state_fw)\n",
    "\n",
    "            # backward LSTM\n",
    "            bw_output, bw_state_h, bw_state_c = self.build_lstm(False)(x, initial_state=initial_state_bw)\n",
    "\n",
    "            x = tf.concat([fw_output, bw_output], -1)\n",
    "            x = self.reshape_pyramidal(x)\n",
    "\n",
    "            initial_state_fw = [fw_state_h, fw_state_c]\n",
    "            initial_state_bw = [bw_state_h, bw_state_c]\n",
    "            \n",
    "            # store the pyramidal lstm structure\n",
    "            pyramidal_layer_name = \"Pyramid LSTM Layer \" + str(pyramid_layer_number)\n",
    "            self.layer_info[pyramidal_layer_name] = x.shape\n",
    "            \n",
    "        return x, (fw_state_h, fw_state_c), (bw_state_h, bw_state_c)\n",
    "    \n",
    "    def build_lstm(self, back=True):\n",
    "        '''\n",
    "        build LSTM layer for forward and backward\n",
    "        '''\n",
    "        return tf.keras.layers.LSTM(units=self.lstm_units, \n",
    "                                    return_sequences=True, \n",
    "                                    return_state=True, \n",
    "                                    go_backwards=back)\n",
    "    \n",
    "    def reshape_pyramidal(self, outputs):\n",
    "        '''\n",
    "        After concatenating forward and backward outputs\n",
    "        return the reshaped output\n",
    "        '''\n",
    "        batch_size, time_steps, num_units = outputs.shape\n",
    "    \n",
    "        return tf.reshape(outputs, (batch_size, -1, num_units * 2))\n",
    "    \n",
    "    def summary(self):\n",
    "        print(\"{:30} {:30}\".format(\"Layer Name\", \"Layer Shape\"))\n",
    "        print(\"{:30} {:30}\".format(\"------------\", \"-------------\"))\n",
    "        for key, value in self.layer_info.items():\n",
    "            print(\"{:30} {:30}\".format(str(key), str(value)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (1, 64, 1024)\n",
      "Encoder forward state h shape: (batch size, units) (1, 256)\n",
      "Encoder backward state h shape: (batch size, units) (1, 256)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(lstm_units=LSTM_UNITS, \n",
    "                  final_units=FINAL_TIMESTEP, \n",
    "                  batch_sz=BATCH_SIZE, \n",
    "                  mfcc_dims=N_FILTER+1)\n",
    "\n",
    "# If set the batch size greater than 4, memory of GPU will run out\n",
    "sample_output, (fw_sample_state_h, fw_sample_state_c), bw_sample_state = encoder(example_input_batch)\n",
    "\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder forward state h shape: (batch size, units) {}'.format(fw_sample_state_h.shape))\n",
    "print ('Encoder backward state h shape: (batch size, units) {}'.format(bw_sample_state[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Name                     Layer Shape                   \n",
      "------------                   -------------                 \n",
      "Input Layer                    (1, 1664, 1)                  \n",
      "Convolution Feature Layer      (1, 128, 32)                  \n",
      "Convolution Layer 1            (1, 128, 32)                  \n",
      "Convolution Layer 2            (1, 128, 64)                  \n",
      "Pyramid LSTM Layer 1           (1, 64, 1024)                 \n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(LuongAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # query hidden state shape == (batch_size, hidden size)\n",
    "        # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # values shape == (batch_size, max_len, hidden size)\n",
    "        # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (1, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (1, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = LuongAttention(10)\n",
    "attention_result, attention_weights = attention_layer(fw_sample_state_h, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, target_sz, embedding_dim, decoder_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.decoder_units = decoder_units\n",
    "        self.embedding = tf.keras.layers.Embedding(target_sz, embedding_dim)\n",
    "        \n",
    "        # build layer info dictionary\n",
    "        self.layer_info = dict()\n",
    "        \n",
    "        # attention model\n",
    "        self.attention = LuongAttention(self.decoder_units)\n",
    "        \n",
    "        # decoder model\n",
    "        self.lstm = tf.keras.layers.LSTM(units=self.decoder_units, return_sequences=True, return_state=True)\n",
    "        self.fc1 = tf.keras.layers.Dense(32)\n",
    "        self.fc2 = tf.keras.layers.Dense(target_sz)\n",
    "\n",
    "\n",
    "    def call(self, inputs, enc_hidden_h, enc_hidden_c, enc_output):\n",
    "        '''\n",
    "        build LSTM decoder\n",
    "        '''\n",
    "        self.layer_info[\"Input Layer\"] = inputs.shape\n",
    "        \n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(enc_hidden_h, enc_output)\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(inputs)\n",
    "        self.layer_info[\"Embedding Layer\"] = x.shape\n",
    "\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # passing the concatenated vector to the LSTM\n",
    "        output, state_h, state_c = self.lstm(x)\n",
    "        self.layer_info[\"Decoder LSTM Output Layer\"] = output.shape\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[-1]))\n",
    "\n",
    "        # output shape == (batch_size, phoneme size)\n",
    "        x = self.fc1(output)\n",
    "        self.layer_info[\"Dense Layer 1\"] = output.shape\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        self.layer_info[\"Output Layer 1\"] = x.shape\n",
    "\n",
    "        return x, (state_h, state_c), attention_weights\n",
    "    \n",
    "    def summary(self):\n",
    "        print(\"{:30} {:30}\".format(\"Layer Name\", \"Layer Shape\"))\n",
    "        print(\"{:30} {:30}\".format(\"------------\", \"-------------\"))\n",
    "        for key, value in self.layer_info.items():\n",
    "            print(\"{:30} {:30}\".format(str(key), str(value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, phoneme size) (1, 22)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(target_sz=PHONEME_SIZE, \n",
    "                  embedding_dim=EMBEDDING_DIM, \n",
    "                  decoder_units=LSTM_UNITS, \n",
    "                  batch_sz=BATCH_SIZE)\n",
    "\n",
    "sample_target_size = tf.random.uniform((BATCH_SIZE, 1))\n",
    "sample_decoder_output, sample_decoder_hidden, attention_weights = decoder(\n",
    "    inputs=sample_target_size, \n",
    "    enc_hidden_h=fw_sample_state_h, \n",
    "    enc_hidden_c=fw_sample_state_c, \n",
    "    enc_output=sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, phoneme size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Name                     Layer Shape                   \n",
      "------------                   -------------                 \n",
      "Input Layer                    (1, 1)                        \n",
      "Embedding Layer                (1, 1, 64)                    \n",
      "Decoder LSTM Output Layer      (1, 1, 256)                   \n",
      "Dense Layer 1                  (1, 256)                      \n",
      "Output Layer 1                 (1, 22)                       \n"
     ]
    }
   ],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, \n",
    "                                                            reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, targ_tokenizer, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        # forward algorithm\n",
    "        enc_output, (enc_hidden_h, enc_hidden_c), bw_enc_hidden = encoder(inp)\n",
    "        dec_hidden_h, dec_hidden_c = enc_hidden_h, enc_hidden_c\n",
    "        dec_input = tf.expand_dims([targ_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # passing enc_output to the decoder\n",
    "            predictions, (dec_hidden_h, dec_hidden_c), _ = decoder(dec_input, dec_hidden_h, dec_hidden_c, enc_output)\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "            # using teacher forcing\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "    \n",
    "    # backward algorithm\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  Batch      Loss   Time(s)\n",
      "    1      0    0.6882    0.6330\n",
      "    1    100    0.6891    51.2606\n",
      "    1    200    0.8342    102.1916\n",
      "    1    300    0.4711    153.3163\n",
      "    1    400    0.8550    204.1083\n",
      "    1    500    0.9302    256.5354\n",
      "    1    600    0.6007    309.6439\n",
      "    1    700    0.5251    363.6547\n",
      "    1    800    0.5626    416.5011\n",
      "    1    900    0.8531    469.4220\n",
      "    1   1000    0.4274    521.2306\n",
      "    1   1100    0.8208    573.5639\n",
      "    1   1200    0.4818    627.3429\n",
      "    1   1300    0.7554    680.2439\n",
      "    1   1400    0.5564    732.1521\n",
      "    1   1500    0.5351    785.7498\n",
      "    1   1600    0.6108    839.4648\n",
      "    1   1700    0.5453    892.0658\n",
      "    1   1800    0.6421    943.9655\n",
      "    1   1900    0.9431    996.5505\n",
      "Epoch  Batch      Loss   Time(s)\n",
      "    1   2000    0.4778    1050.4100\n",
      "    1   2100    0.5239    1102.7270\n",
      "    1   2200    0.4041    1155.2572\n",
      "    1   2300    0.8320    1207.2364\n",
      "    1   2400    0.5383    1259.3282\n",
      "    1   2500    0.8464    1311.3132\n",
      "    1   2600    0.6431    1365.6202\n",
      "    1   2700    0.6274    1418.9411\n",
      "    1   2800    0.7690    1472.5411\n",
      "    1   2900    0.8315    1524.8138\n",
      "    1   3000    0.8146    1578.3104\n",
      "    1   3100    0.5774    1630.5374\n",
      "    1   3200    0.4819    1682.9447\n",
      "    1   3300    0.6699    1735.5272\n",
      "    1   3400    0.6014    1788.8178\n",
      "    1   3500    0.5704    1842.0677\n",
      "    1   3600    0.6902    1894.4817\n",
      "    1   3700    0.7472    1946.2767\n",
      "    1   3800    0.5002    1998.7598\n",
      "    1   3900    0.5881    2052.4679\n",
      "Epoch  Batch      Loss   Time(s)\n",
      "    1   4000    0.5871    2104.7069\n",
      "    1   4100    0.6359    2158.5660\n",
      "    1   4200    0.7065    2210.3627\n",
      "    1   4300    0.6364    2262.3927\n",
      "    1   4400    0.8336    2315.3184\n",
      "    1   4500    0.8059    2368.4654\n",
      "    1   4600    0.5907    2422.3134\n",
      "    1   4700    0.5014    2476.4024\n",
      "    1   4800    0.7268    2532.5675\n",
      "    1   4900    0.4335    2587.4881\n",
      "    1   5000    0.9039    2642.8768\n",
      "    1   5100    0.7566    2695.9555\n",
      "    1   5200    0.9428    2748.4679\n",
      "    1   5300    0.5837    2803.0514\n",
      "    1   5400    0.5926    2856.3947\n",
      "    1   5500    0.5717    2908.8082\n",
      "    1   5600    0.5592    2959.6388\n",
      "    1   5700    0.5285    3012.6750\n",
      "    1   5800    0.7344    3066.8550\n",
      "    1   5900    0.8385    3119.8630\n",
      "Epoch  Batch      Loss   Time(s)\n",
      "    1   6000    0.6178    3171.5474\n",
      "    1   6100    0.8800    3222.5414\n",
      "    1   6200    0.3576    3274.4371\n",
      "    1   6300    0.4529    3328.6143\n",
      "    1   6400    0.5332    3381.9735\n",
      "    1   6500    0.6721    3432.9359\n",
      "    1   6600    0.9018    3484.9361\n",
      "    1   6700    0.6423    3538.5131\n",
      "    1   6800    0.7994    3591.8332\n",
      "    1   6900    0.8115    3646.2892\n",
      "    1   7000    0.5829    3699.8622\n",
      "    1   7100    0.6936    3752.0272\n",
      "    1   7200    0.7242    3804.4262\n",
      "    1   7300    0.6699    3855.8845\n",
      "    1   7400    0.5370    3909.0451\n",
      "    1   7500    0.4497    3961.0182\n",
      "    1   7600    0.7673    4012.9427\n",
      "    1   7700    0.5019    4064.9318\n",
      "    1   7800    0.7782    4117.7426\n",
      "    1   7900    0.4801    4168.9102\n",
      "Epoch  Batch      Loss   Time(s)\n",
      "    1   8000    0.7588    4221.9504\n",
      "    1   8100    0.6098    4274.4624\n",
      "    1   8200    0.4921    4327.2624\n",
      "    1   8300    0.7015    4380.1929\n",
      "    1   8400    0.4643    4432.6835\n",
      "    1   8500    0.7178    4486.4441\n",
      "    1   8600    0.5919    4541.6041\n",
      "    1   8700    0.4827    4595.4510\n",
      "    1   8800    0.4346    4647.2370\n",
      "    1   8900    0.3896    4701.0436\n",
      "    1   9000    0.6107    4757.6193\n",
      "    1   9100    0.6019    4811.4223\n",
      "    1   9200    0.5114    4862.8924\n",
      "    1   9300    0.4871    4915.6630\n",
      "    1   9400    0.4417    4967.6040\n",
      "    1   9500    0.6648    5019.1660\n",
      "    1   9600    0.5683    5070.4211\n",
      "    1   9700    0.4306    5121.7211\n",
      "    1   9800    0.7251    5177.2983\n",
      "    1   9900    0.5313    5232.0792\n",
      "Epoch  Batch      Loss   Time(s)\n",
      "    1  10000    0.6078    5283.7950\n",
      "    1  10100    0.6568    5335.5978\n",
      "    1  10200    0.3930    5388.0486\n",
      "    1  10300    0.3820    5440.3574\n",
      "    1  10400    0.4808    5492.3486\n",
      "    1  10500    0.4199    5545.0084\n",
      "    1  10600    0.5721    5596.7064\n",
      "    1  10700    0.6425    5649.9599\n",
      "    1  10800    0.5361    5701.6478\n",
      "    1  10900    0.4061    5753.0998\n",
      "    1  11000    0.3653    5806.0695\n",
      "    1  11100    0.5258    5859.0071\n",
      "    1  11200    0.4124    5912.1573\n",
      "    1  11300    0.3473    5966.3056\n",
      "    1  11400    0.8325    6021.0462\n",
      "    1  11500    0.4937    6073.8244\n",
      "    1  11600    0.3914    6125.4635\n",
      "    1  11700    0.5652    6177.2280\n",
      "    1  11800    0.5408    6229.1136\n",
      "    1  11900    0.5382    6280.4595\n",
      "Epoch  Batch      Loss   Time(s)\n",
      "    1  12000    0.4723    6331.9368\n",
      "    1  12100    0.4805    6384.2959\n",
      "    1  12200    0.5424    6436.1155\n",
      "    1  12300    0.3474    6490.4927\n",
      "    1  12400    0.3603    6541.8154\n",
      "    1  12500    0.3637    6592.7764\n",
      "    1  12600    0.6552    6643.4184\n",
      "    1  12700    0.9522    6696.8850\n",
      "    1  12800    0.4143    6748.7064\n",
      "    1  12900    0.5595    6803.4311\n",
      "    1  13000    0.7279    6857.7933\n",
      "    1  13100    0.4821    6908.7404\n",
      "    1  13200    0.4905    6959.6837\n",
      "    1  13300    0.3618    7010.1424\n",
      "    1  13400    0.3966    7060.9163\n",
      "    1  13500    0.5456    7112.4000\n",
      "    1  13600    0.6043    7163.2806\n",
      "    1  13700    0.6114    7214.0613\n",
      "    1  13800    0.6310    7264.8774\n",
      "    1  13900    0.6558    7315.6422\n",
      "Epoch  Batch      Loss   Time(s)\n",
      "    1  14000    0.3915    7365.8737\n",
      "    1  14100    0.4497    7416.5159\n",
      "    1  14200    0.3718    7467.3730\n",
      "    1  14300    0.6018    7517.9470\n",
      "    1  14400    0.6604    7568.2901\n",
      "    1  14500    0.3441    7618.9064\n",
      "    1  14600    0.5740    7669.9982\n",
      "    1  14700    0.5451    7722.7249\n",
      "    1  14800    0.9478    7773.9685\n",
      "    1  14900    0.5842    7826.0940\n",
      "    1  15000    0.5159    7877.6947\n",
      "    1  15100    0.4556    7929.6490\n",
      "    1  15200    0.3877    7980.6256\n",
      "    1  15300    0.3691    8031.0077\n",
      "    1  15400    0.4103    8082.1896\n",
      "    1  15500    0.5045    8135.5470\n",
      "    1  15600    0.5379    8186.2690\n",
      "    1  15700    0.3399    8237.1557\n",
      "    1  15800    0.3663    8287.4054\n",
      "    1  15900    0.4566    8337.9543\n",
      "Epoch  Batch      Loss   Time(s)\n",
      "    1  16000    0.9135    8388.9315\n",
      "    1  16100    0.5763    8439.8082\n",
      "    1  16200    0.5202    8489.9058\n",
      "    1  16300    0.5998    8540.5204\n",
      "    1  16400    0.3586    8592.6296\n",
      "    1  16500    0.5699    8644.0795\n",
      "    1  16600    0.3687    8694.8162\n",
      "    1  16700    0.4363    8745.0502\n",
      "    1  16800    0.5028    8796.0318\n",
      "    1  16900    0.4868    8846.8235\n",
      "    1  17000    0.3455    8897.9136\n",
      "    1  17100    0.4247    8948.2022\n",
      "    1  17200    0.4592    9000.3078\n",
      "    1  17300    0.3220    9052.3758\n",
      "    1  17400    0.4478    9103.0177\n",
      "    1  17500    0.3256    9153.7827\n",
      "    1  17600    0.5497    9203.9894\n",
      "    1  17700    0.6242    9254.7540\n",
      "    1  17800    0.3431    9305.8676\n",
      "    1  17900    0.4877    9357.6412\n",
      "Epoch  Batch      Loss   Time(s)\n",
      "    1  18000    0.5974    9407.8523\n",
      "    1  18100    0.5180    9459.3253\n",
      "    1  18200    0.5344    9512.2218\n",
      "    1  18300    0.4994    9566.4332\n",
      "    1  18400    0.5615    9619.8800\n",
      "    1  18500    0.5092    9670.9813\n",
      "    1  18600    0.3527    9722.0145\n",
      "    1  18700    0.5542    9772.9244\n",
      "    1  18800    0.5001    9823.8855\n",
      "    1  18900    0.4896    9875.5548\n",
      "    1  19000    0.5513    9932.6878\n",
      "    1  19100    0.3215    9985.9367\n",
      "    1  19200    0.5583    10036.7511\n",
      "    1  19300    0.5514    10087.8501\n",
      "    1  19400    0.5983    10138.8862\n",
      "    1  19500    0.5856    10189.5713\n",
      "    1  19600    0.3718    10242.3083\n",
      "    1  19700    0.3354    10295.2459\n",
      "    1  19800    0.4534    10346.2762\n",
      "    1  19900    0.5677    10399.9105\n",
      "Epoch 1 Loss 0.5614\n",
      "Time taken for 1 epoch 174.1936 min\n",
      "\n",
      "Epoch  Batch      Loss   Time(s)\n",
      "    2      0    0.3571    0.6580\n",
      "    2    100    0.3836    53.3063\n",
      "    2    200    0.6095    104.5596\n",
      "    2    300    0.5579    155.6813\n",
      "    2    400    0.7349    207.5134\n",
      "    2    500    0.4668    260.6091\n",
      "    2    600    0.3383    312.0709\n",
      "    2    700    0.3848    363.4976\n",
      "    2    800    0.5819    414.7786\n",
      "    2    900    0.5618    465.6522\n",
      "    2   1000    0.5178    517.0018\n",
      "    2   1100    0.4692    568.3490\n",
      "    2   1200    0.7455    619.6572\n",
      "    2   1300    0.4223    670.6982\n",
      "    2   1400    0.4860    721.9088\n",
      "    2   1500    0.4608    773.2218\n",
      "    2   1600    0.3646    824.6099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2   1700    0.4221    875.9956\n",
      "    2   1800    0.3279    926.8376\n",
      "    2   1900    0.5865    980.3483\n",
      "Epoch  Batch      Loss   Time(s)\n",
      "    2   2000    0.5202    1034.1014\n",
      "    2   2100    0.4518    1087.3381\n",
      "    2   2200    0.3180    1140.1097\n",
      "    2   2300    0.5677    1191.8598\n",
      "    2   2400    0.3391    1243.2425\n",
      "    2   2500    0.4984    1294.4937\n",
      "    2   2600    0.3748    1345.8488\n",
      "    2   2700    0.4327    1397.1319\n",
      "    2   2800    0.4869    1448.2180\n",
      "    2   2900    0.5515    1499.6033\n",
      "    2   3000    0.5510    1550.7154\n",
      "    2   3100    0.4493    1601.9682\n",
      "    2   3200    0.3313    1652.6252\n",
      "    2   3300    0.4397    1703.9034\n",
      "    2   3400    0.6380    1756.1146\n",
      "    2   3500    0.5681    1807.4609\n",
      "    2   3600    0.5468    1859.0687\n",
      "    2   3700    0.3793    1909.7407\n",
      "    2   3800    0.5036    1961.4413\n",
      "    2   3900    0.3485    2012.5843\n",
      "Epoch  Batch      Loss   Time(s)\n",
      "    2   4000    0.5063    2064.0700\n",
      "    2   4100    0.5414    2114.9146\n",
      "    2   4200    0.4030    2165.9572\n",
      "    2   4300    0.3503    2217.5639\n",
      "    2   4400    0.3251    2268.5349\n",
      "    2   4500    0.4566    2319.7005\n",
      "    2   4600    0.5770    2370.3087\n",
      "    2   4700    0.3747    2421.5157\n",
      "    2   4800    0.3548    2472.6037\n",
      "    2   4900    0.7264    2523.6989\n",
      "    2   5000    0.4160    2574.5446\n",
      "    2   5100    0.5747    2625.3983\n",
      "    2   5200    0.5411    2676.6330\n",
      "    2   5300    0.3494    2727.6097\n",
      "    2   5400    0.5255    2778.6587\n",
      "    2   5500    0.4310    2829.2529\n",
      "    2   5600    0.4350    2880.3365\n",
      "    2   5700    0.4935    2931.2937\n",
      "    2   5800    0.4874    2982.7757\n",
      "    2   5900    0.4679    3033.6005\n",
      "Epoch  Batch      Loss   Time(s)\n",
      "    2   6000    0.3756    3084.3509\n",
      "    2   6100    0.3406    3135.2865\n",
      "    2   6200    0.5605    3186.2265\n",
      "    2   6300    0.4529    3237.1617\n",
      "    2   6400    0.6138    3287.6102\n",
      "    2   6500    0.5848    3345.1967\n",
      "    2   6600    0.3797    3401.4684\n",
      "    2   6700    0.4852    3452.4141\n",
      "    2   6800    0.3655    3503.3662\n",
      "    2   6900    0.7349    3553.8033\n",
      "    2   7000    0.6826    3604.9652\n",
      "    2   7100    0.4859    3657.1080\n",
      "    2   7200    0.3881    3708.0821\n",
      "    2   7300    0.5938    3758.7867\n",
      "    2   7400    0.3385    3809.5458\n",
      "    2   7500    0.3632    3860.3956\n",
      "    2   7600    0.3421    3911.5501\n",
      "    2   7700    0.3633    3962.4487\n",
      "    2   7800    0.3743    4012.9847\n",
      "    2   7900    0.5683    4063.7763\n",
      "Epoch  Batch      Loss   Time(s)\n",
      "    2   8000    0.4381    4117.8579\n",
      "    2   8100    0.3403    4169.0410\n",
      "    2   8200    0.4082    4220.2591\n",
      "    2   8300    0.3735    4271.2152\n",
      "    2   8400    0.3475    4322.2558\n",
      "    2   8500    0.3921    4373.8495\n",
      "    2   8600    0.4574    4425.1340\n",
      "    2   8700    0.5666    4475.8873\n",
      "    2   8800    0.4687    4527.1659\n",
      "    2   8900    0.5412    4578.5409\n",
      "    2   9000    0.3778    4630.2576\n",
      "    2   9100    0.5137    4681.3672\n",
      "    2   9200    0.6508    4731.9902\n",
      "    2   9300    0.5815    4783.0663\n",
      "    2   9400    0.3659    4834.3334\n",
      "    2   9500    0.4812    4885.3445\n",
      "    2   9600    0.3536    4936.0296\n",
      "    2   9700    0.9459    4987.7126\n",
      "    2   9800    0.3594    5038.9768\n",
      "    2   9900    0.3685    5090.3152\n",
      "Epoch  Batch      Loss   Time(s)\n",
      "    2  10000    0.3680    5141.4898\n",
      "    2  10100    0.5994    5192.0999\n",
      "    2  10200    0.5453    5243.1569\n",
      "    2  10300    0.4387    5294.7347\n",
      "    2  10400    0.5644    5345.9023\n",
      "    2  10500    0.5759    5397.0856\n",
      "    2  10600    0.5397    5447.9736\n",
      "    2  10700    0.4757    5498.8656\n",
      "    2  10800    0.5645    5549.8782\n",
      "    2  10900    0.3699    5600.6063\n",
      "    2  11000    0.4726    5651.4176\n",
      "    2  11100    0.3492    5702.4697\n",
      "    2  11200    0.4628    5753.6127\n",
      "    2  11300    0.5841    5804.5584\n",
      "    2  11400    0.3385    5854.8484\n",
      "    2  11500    0.5533    5905.9600\n",
      "    2  11600    0.5118    5957.2001\n",
      "    2  11700    0.4376    6008.4797\n",
      "    2  11800    0.4580    6059.1514\n",
      "    2  11900    0.3465    6109.8445\n",
      "Epoch  Batch      Loss   Time(s)\n",
      "    2  12000    0.4984    6160.7463\n",
      "    2  12100    0.5540    6211.9458\n",
      "    2  12200    0.4994    6262.9789\n",
      "    2  12300    0.4019    6313.3875\n",
      "    2  12400    0.5594    6364.5468\n",
      "    2  12500    0.4129    6415.4109\n",
      "    2  12600    0.4481    6466.4242\n",
      "    2  12700    0.3462    6516.7463\n",
      "    2  12800    0.3271    6567.7978\n",
      "    2  12900    0.5430    6619.0719\n",
      "    2  13000    0.4757    6670.1729\n",
      "    2  13100    0.4340    6721.0789\n",
      "    2  13200    0.4474    6771.5255\n",
      "    2  13300    0.3823    6822.6276\n",
      "    2  13400    0.3236    6873.6202\n",
      "    2  13500    0.5082    6924.9672\n",
      "    2  13600    0.4749    6975.8535\n",
      "    2  13700    0.4695    7026.9621\n",
      "    2  13800    0.3756    7078.0105\n",
      "    2  13900    0.4897    7129.3343\n",
      "Epoch  Batch      Loss   Time(s)\n",
      "    2  14000    0.3657    7180.2700\n",
      "    2  14100    0.3864    7230.9077\n",
      "    2  14200    0.5225    7283.4547\n",
      "    2  14300    0.4539    7334.6027\n",
      "    2  14400    0.5030    7385.6624\n",
      "    2  14500    0.4854    7436.1155\n",
      "    2  14600    0.4347    7487.5112\n",
      "    2  14700    0.6746    7538.5218\n",
      "    2  14800    0.5843    7589.7119\n",
      "    2  14900    0.6672    7640.5505\n",
      "    2  15000    0.5783    7691.1001\n",
      "    2  15100    0.7315    7742.1643\n",
      "    2  15200    0.4495    7793.2649\n",
      "    2  15300    0.7004    7844.2805\n",
      "    2  15400    0.4055    7894.7917\n",
      "    2  15500    0.5724    7945.7059\n",
      "    2  15600    0.6239    7996.8496\n",
      "    2  15700    0.2969    8048.0428\n",
      "    2  15800    0.3427    8099.0489\n",
      "    2  15900    0.3364    8149.5450\n",
      "Epoch  Batch      Loss   Time(s)\n",
      "    2  16000    0.4531    8200.6083\n",
      "    2  16100    0.5654    8251.6029\n",
      "    2  16200    0.6755    8302.4425\n",
      "    2  16300    0.5403    8353.0826\n",
      "    2  16400    0.4798    8404.1838\n",
      "    2  16500    0.4299    8455.1676\n",
      "    2  16600    0.3660    8506.0853\n",
      "    2  16700    0.3360    8557.2629\n",
      "    2  16800    0.6092    8607.9171\n",
      "    2  16900    0.3630    8659.1626\n",
      "    2  17000    0.4912    8710.1988\n",
      "    2  17100    0.3295    8761.2988\n",
      "    2  17200    0.4705    8811.8204\n",
      "    2  17300    0.3351    8862.8491\n",
      "    2  17400    0.3931    8914.1485\n",
      "    2  17500    0.3599    8965.7055\n",
      "    2  17600    0.3680    9037.0356\n",
      "    2  17700    0.3620    9154.8182\n",
      "    2  17800    0.5683    9273.6926\n",
      "    2  17900    0.5242    9386.0155\n",
      "Epoch  Batch      Loss   Time(s)\n",
      "    2  18000    0.4630    9503.8266\n",
      "    2  18100    0.4180    9620.2444\n",
      "    2  18200    0.3701    9737.6716\n",
      "    2  18300    0.4533    9851.8738\n",
      "    2  18400    0.6738    9954.5712\n",
      "    2  18500    0.5495    10008.1192\n",
      "    2  18600    0.5019    10063.9715\n",
      "    2  18700    0.4365    10115.3956\n",
      "    2  18800    0.4330    10165.9288\n",
      "    2  18900    0.5561    10217.8657\n",
      "    2  19000    0.3636    10268.2474\n",
      "    2  19100    0.3602    10318.3680\n",
      "    2  19200    0.3587    10368.9041\n",
      "    2  19300    0.4548    10419.1499\n",
      "    2  19400    0.3680    10470.7889\n",
      "    2  19500    0.3474    10520.7840\n",
      "    2  19600    0.6531    10573.3601\n",
      "    2  19700    0.6063    10627.0261\n",
      "    2  19800    0.5653    10678.6837\n",
      "    2  19900    0.4575    10730.5457\n",
      "Epoch 2 Loss 0.4739\n",
      "Time taken for 1 epoch 179.7277 min\n",
      "\n",
      "Epoch  Batch      Loss   Time(s)\n",
      "    3      0    0.3531    0.6630\n",
      "    3    100    0.3737    53.4695\n",
      "    3    200    0.5399    105.4089\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-ae91dd254791>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSTEP_PER_EPOCH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0minp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mbatch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphoneme_tokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    452\u001b[0m     \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mRUN_FUNCTIONS_EAGERLY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-35eb96c92dde>\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(inp, targ, targ_tokenizer, enc_hidden)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mvariables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1012\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\Tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_grad.py\u001b[0m in \u001b[0;36m_ReshapeGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    611\u001b[0m         \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m         message=\"Converting sparse IndexedSlices to a dense Tensor.*\")\n\u001b[1;32m--> 613\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    614\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m   \"\"\"\n\u001b[1;32m--> 131\u001b[1;33m   \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m   \u001b[0mtensor_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_set_static_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m   8099\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[0;32m   8100\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Reshape\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 8101\u001b[1;33m         name, _ctx._post_execution_callbacks, tensor, shape)\n\u001b[0m\u001b[0;32m   8102\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8103\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run eagerly will make tensorflow run step by step or else it will raise\n",
    "# ValueError: tf.function-decorated function tried to create variables on non-first call.\n",
    "# similar to Pytorch, which is a dynamic graph for deep learning\n",
    "tf.config.experimental_run_functions_eagerly(True)\n",
    "\n",
    "EPOCHS = 10\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    start = time.time()\n",
    "\n",
    "    # enc_hidden = encoder.initialize_hidden_state()\n",
    "    enc_hidden = None\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(STEP_PER_EPOCH)):\n",
    "        inp = tf.expand_dims(inp, 2)\n",
    "        batch_loss = train_step(inp, targ, phoneme_tokenizer, enc_hidden)\n",
    "        \n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        if batch % 2000 == 0:\n",
    "            print(\"\\n{:>5}  {:>5}  {:>8}  {:>10}\".format(\"Epoch\", \"Batch\", \"Loss\", \"Time(s)\"))\n",
    "            \n",
    "        if batch % 100 == 0:\n",
    "            print('{:>5}  {:>5}    {:.4f}  {:>10}'.format(epoch, \n",
    "                                                          batch, \n",
    "                                                          batch_loss.numpy(), \n",
    "                                                          str(round(time.time() - start, 2))))\n",
    "\n",
    "    # saving (checkpoint) the model every epoch\n",
    "    checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / STEP_PER_EPOCH))\n",
    "    print('Time taken for 1 epoch {:.4f} min\\n'.format((time.time() - start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(inputs, max_input_len, max_output_len, tokenizer=None):\n",
    "    attention_plot = np.zeros((max_output_len, max_input_len))\n",
    "    \n",
    "    inputs = tf.expand_dims(inputs, 0)\n",
    "    inputs = tf.expand_dims(inputs, 2)\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    result = ''\n",
    "\n",
    "    # hidden = [tf.zeros((1, units))]\n",
    "    hidden = None\n",
    "    enc_out, enc_hidden_h, enc_hidden_c = encoder(inputs)\n",
    "\n",
    "    dec_hidden_h, dec_hidden_c = enc_hidden_h, enc_hidden_c\n",
    "    dec_input = tf.expand_dims([tokenizer.word_index['<start>']], 0)\n",
    "\n",
    "    for t in np.arange(max_output_len):\n",
    "        predictions, dec_hidden, attention_weights = decoder(\n",
    "            inputs=dec_input, \n",
    "            enc_hidden_h=dec_hidden_h, \n",
    "            enc_hidden_c=dec_input, \n",
    "            enc_output=enc_out)\n",
    "\n",
    "        # storing the attention weights to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "        if tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return result, wave, attention_plot\n",
    "\n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, wave, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, input_wav, output_phoneme):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    # ax.set_xticklabels([''] + input_wav, fontdict=fontdict, rotation=90)\n",
    "#     ax.set_xticklabels(range(len(input_wav)))\n",
    "    ax.set_yticklabels([''] + output_phoneme, fontdict=fontdict)\n",
    "\n",
    "    # ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(wave, max_in, max_out, tokenizer):\n",
    "    result, _, attention_plot = predict(wave, max_in, max_out, tokenizer)\n",
    "\n",
    "    print(f'Original Input Length: {len(wave)}')\n",
    "    print(f'Predicted translation: {result}')\n",
    "\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :50]\n",
    "    plot_attention(attention_plot, np.arange(len(wave)), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing with test wave data\n",
    "translate(test_wave, 8, sample_decoder_output.shape[1], phoneme_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
